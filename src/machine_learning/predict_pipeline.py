import argparse
import os
import pandas as pd

from src.machine_learning.feature_validation import DataValidator, FeatureValidationError
from src.machine_learning.artifacts import load_model_processor, load_threshold

def predict_dataframe(df: pd.DataFrame, artifacts_dir: str, do_validate: bool=False, validation_config: dict|None=None) -> pd.DataFrame:
    if df is None or df.empty:
        raise ValueError("ìž…ë ¥ ë°ì´í„°ê°€ ë¹„ì–´ ìžˆìŠµë‹ˆë‹¤.")

    # ë¼ë²¨ì´ ì„žì—¬ ìžˆìœ¼ë©´ ì œê±°
    if "depression_label" in df.columns:
        df = df.drop(columns=["depression_label"])

    # (ì˜µì…˜) ìœ íš¨ì„± ê²€ì‚¬
    if do_validate:
        if validation_config is None:
            raise ValueError("do_validate=True ì¸ ê²½ìš° validation_config í•„ìš”.")
        v = DataValidator(df, validation_config)
        report, df_valid, _ = v.validate_features()
        if report.get("problems", 0) > 0:
            raise FeatureValidationError(f"ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨: {report}")
        df = df_valid

    # ì•„í‹°íŒ©íŠ¸ ë¡œë“œ
    model, processor = load_model_processor(artifacts_dir)
    thr = load_threshold(artifacts_dir, default=0.5)

    # ë³€í™˜
    X = processor.transform(df)

    # ìˆ«ìží˜•ë§Œ ì‚¬ìš© + í•™ìŠµ ì‹œ ì»¬ëŸ¼ ìˆœì„œë¡œ ì •ë ¬
    import numpy as _np
    X = X.select_dtypes(include=[_np.number]).copy()
    if hasattr(model, "feature_names_in_"):
        missing = [c for c in model.feature_names_in_ if c not in X.columns]
        if missing:
            raise ValueError(f"ì˜ˆì¸¡ ìž…ë ¥ì— í•™ìŠµ ì‹œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")
        X = X.loc[:, model.feature_names_in_]

    # ì˜ˆì¸¡
    if hasattr(model, "predict_proba"):
        proba = model.predict_proba(X)[:, 1]
    elif hasattr(model, "decision_function"):
        proba = 1/(1+_np.exp(-model.decision_function(X)))
    else:
        proba = model.predict(X).astype(float)
    flag = (proba >= thr).astype(int)

    out = df.copy()
    out["risk_proba"] = proba
    out["risk_flag"]  = flag
    return out

def main():
    ap = argparse.ArgumentParser(description="Predict using saved artifacts (model, processor, threshold)")
    ap.add_argument("--in", dest="in_path", required=True, help="ìž…ë ¥ CSV ê²½ë¡œ (íŠ¹ì§•ë§Œ)")
    ap.add_argument("--artifacts", required=True, help="artifacts ë””ë ‰í† ë¦¬ (model.pkl, processor.pkl, threshold.json)")
    ap.add_argument("--out", required=True, help="ì¶œë ¥ CSV ê²½ë¡œ")
    ap.add_argument("--validate", action="store_true", help="ì‹¤í–‰ ì‹œ feature validation ìˆ˜í–‰(ì˜µì…˜)")
    args = ap.parse_args()

    # ðŸ‘‰ 10ê°œ ìŠ¤í‚¤ë§ˆ
    VALIDATION_CONFIG = {
        "expected_columns": [
            "total_usage_daily","total_usage_weekly",
            "late_night_ratio","sns_ent_ratio",
            "session_length_max","session_length_mean",
            "bounce_ratio","avg_tab_cnt","search_freq","repeat_site_ratio"
        ],
        "ratio_columns": ["late_night_ratio","sns_ent_ratio","bounce_ratio","repeat_site_ratio"],
        "float_columns": ["total_usage_daily","total_usage_weekly","session_length_max","session_length_mean"],
        "int_columns": ["avg_tab_cnt","search_freq"],
        "date_columns": []
    }

    df = pd.read_csv(args.in_path)
    res = predict_dataframe(
        df=df,
        artifacts_dir=args.artifacts,
        do_validate=args.validate,
        validation_config=VALIDATION_CONFIG if args.validate else None,
    )
    os.makedirs(os.path.dirname(args.out) or ".", exist_ok=True)
    res.to_csv(args.out, index=False)
    print(f"[OK] wrote {args.out} (rows={len(res)})")

if __name__ == "__main__":
    main()
