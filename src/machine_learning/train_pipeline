import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    roc_auc_score,
    f1_score,
)
import joblib

# 사용자 정의 클래스 임포트
from src.machine_learning.feature_validation import DataValidator, FeatureValidationError
from src.machine_learning.data_processor import DataProcessor, DataProcessingError


def train_and_save_model(
    data_path: str,
    model_save_path: str,
    scaler_save_path: str,
    model_cls=RandomForestClassifier,
    **model_kwargs,
):
    """
    데이터 로드부터 모델 학습 및 저장까지의 전체 파이프라인을 실행합니다.

    Args:
        data_path (str): 학습 데이터 파일 경로.
        model_save_path (str): 학습된 모델을 저장할 경로.
        scaler_save_path (str): 학습된 스케일러를 저장할 경로.
        model_cls (class): 사용할 모델 클래스 (기본값: RandomForestClassifier).
        **model_kwargs: 모델 초기화 시 전달할 추가 인자.
    """
    try:
        # === 0. 저장 경로 보장 ===
        os.makedirs(os.path.dirname(model_save_path), exist_ok=True)
        os.makedirs(os.path.dirname(scaler_save_path), exist_ok=True)

        # === 1. 데이터 로드 ===
        df = pd.read_csv(data_path)
        print("✅ 데이터 로드 완료.")

        # === 2. 유효성 검사 (Validation) ===
        config = {
            "expected_columns": [
                "period_start", "period_end",
                "session_length_max", "session_length_mean",
                "avg_tab_cnt", "search_freq", "ad_click_rate",
                "depression_label"
            ],
            "ratio_columns": ["ad_click_rate"],
            "float_columns": ["session_length_max", "session_length_mean"],
            "int_columns": ["avg_tab_cnt", "search_freq"],
        }
        validator = DataValidator(df, config)
        report, df_validated, _ = validator.validate_features()

        if report["problems"] > 0:
            raise FeatureValidationError(
                "데이터 유효성 검사 실패. 'feature_validation_failures.csv'를 확인하세요."
            )
        print("✅ 데이터 유효성 검사 통과.")

        # === 3. Feature / Target 분리 ===
        X = df_validated.drop(columns=["depression_label"])
        y = df_validated["depression_label"]

        # 라벨 검증
        if y.isna().sum() > 0:
            raise DataProcessingError("Target 라벨에 결측치가 있습니다.")
        if not set(y.unique()).issubset({0, 1}):
            print("⚠️ 경고: 라벨이 0/1 이진값이 아닐 수 있습니다.")

        # === 4. Train/Test Split ===
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        print(f"✅ 데이터 분리 완료: Train={len(X_train)}, Test={len(X_test)}")

        # === 5. 데이터 전처리 ===
        processor = DataProcessor(X_train)
        X_train_processed, meta = processor.fit_transform()
        X_test_processed = processor.transform(X_test)
        print("✅ 데이터 전처리 완료 (결측치, 이상치, 스케일링).")

        # === 6. 모델 학습 ===
        model = model_cls(**model_kwargs)
        model.fit(X_train_processed, y_train)
        print(f"✅ 모델 학습 완료: {model_cls.__name__}")

        # === 7. 모델 평가 ===
        y_pred = model.predict(X_test_processed)
        print("\n=== 모델 평가 결과 ===")
        print("Classification Report:\n", classification_report(y_test, y_pred))
        print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

        # 추가 성능 지표
        try:
            print("ROC-AUC:", roc_auc_score(y_test, y_pred))
        except ValueError:
            print("ROC-AUC 계산 불가 (라벨이 한쪽에만 있음).")
        print("F1 Score:", f1_score(y_test, y_pred, average="weighted"))

        # === 8. 모델 및 전처리기 저장 ===
        joblib.dump(model, model_save_path)
        joblib.dump(meta["scaler"], scaler_save_path)
        print(f"✅ 모델 저장 완료: {model_save_path}")
        print(f"✅ 스케일러 저장 완료: {scaler_save_path}")

    except (FeatureValidationError, DataProcessingError) as e:
        print(f"❌ 파이프라인 오류: {e}")
    except FileNotFoundError:
        print(f"❌ 파일을 찾을 수 없습니다: {data_path}")
    except Exception as e:
        print(f"❌ 예상치 못한 오류: {e}")


if __name__ == "__main__":
    train_and_save_model(
        data_path="examples/sample_data.csv",
        model_save_path="models/random_forest.pkl",
        scaler_save_path="models/data_scaler.pkl",
        model_cls=RandomForestClassifier,   # 다른 모델로 교체 가능
        n_estimators=200,                   # 모델 파라미터 전달 예시
        random_state=42
    )
